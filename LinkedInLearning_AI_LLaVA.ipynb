{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNi7lTuvu8OqI3QVJCD+yLv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8eb9ed0c6414ed187049026305e0aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d0e4546a30546329cf55d1a62350a7f",
              "IPY_MODEL_511b0c370b7541f990381d764c27f420",
              "IPY_MODEL_c84c400aeb374272a70f0ab2e3ac9689"
            ],
            "layout": "IPY_MODEL_766aa32679574899b556f53f3bb60841"
          }
        },
        "2d0e4546a30546329cf55d1a62350a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d30e2c2c825450b977afb1c0ba10b17",
            "placeholder": "​",
            "style": "IPY_MODEL_e09e28cf9a5c4b51bcebed15141696ba",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "511b0c370b7541f990381d764c27f420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c2bee5ae3a44028c3f55ee1cff574d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d530a3f669c74027aa9173cf814b8844",
            "value": 2
          }
        },
        "c84c400aeb374272a70f0ab2e3ac9689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a7b588d8a8489cb6612e03d8c03aa2",
            "placeholder": "​",
            "style": "IPY_MODEL_449d8ce4f64d4d98b29b08fade27d551",
            "value": " 2/2 [00:01&lt;00:00,  1.59it/s]"
          }
        },
        "766aa32679574899b556f53f3bb60841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d30e2c2c825450b977afb1c0ba10b17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09e28cf9a5c4b51bcebed15141696ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53c2bee5ae3a44028c3f55ee1cff574d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d530a3f669c74027aa9173cf814b8844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43a7b588d8a8489cb6612e03d8c03aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449d8ce4f64d4d98b29b08fade27d551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohitmathurtech/colab_hf_LR_ML_DL/blob/main/LinkedInLearning_AI_LLaVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLAVA\n",
        "  ## Large Language and Vision Assistant"
      ],
      "metadata": {
        "id": "2m7O__X1BGge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ## request : help make http request in python\n",
        "  ## PIL will help get image from URL"
      ],
      "metadata": {
        "id": "iG82pNDoBriA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6Zw20tcA-UA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://github.com/LinkedInLearning/ai-workshop-building-ai-apps-with-hugging-face-models-3922644/blob/40ea81d22444f26b89330d2567bcc6a3093474fc/city.jpg?raw=true\"\n",
        "image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "w4A-T3eJD1L5",
        "outputId": "ba3066d3-f32c-4d27-b798-749c7dc2adda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.47.0\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"image-to-text\", model=\"bczhou/tiny-llava-v1-hf\")\n",
        "\n",
        "max_new_tokens = 200\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prompt = \"USER: <image>What are the things that you see in the picture? What stands out to you the most?\\n ASSISTANT: \"\n",
        "\n",
        "output = pipe(image, prompt=prompt, generate_kwargs={\"max_new_tokens\": max_new_tokens})\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "d8eb9ed0c6414ed187049026305e0aa8",
            "2d0e4546a30546329cf55d1a62350a7f",
            "511b0c370b7541f990381d764c27f420",
            "c84c400aeb374272a70f0ab2e3ac9689",
            "766aa32679574899b556f53f3bb60841",
            "6d30e2c2c825450b977afb1c0ba10b17",
            "e09e28cf9a5c4b51bcebed15141696ba",
            "53c2bee5ae3a44028c3f55ee1cff574d",
            "d530a3f669c74027aa9173cf814b8844",
            "43a7b588d8a8489cb6612e03d8c03aa2",
            "449d8ce4f64d4d98b29b08fade27d551"
          ]
        },
        "id": "sq6rRToRGckH",
        "outputId": "71d9b522-ad10-4d27-b52e-0ae9813a7ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.47.0 in /usr/local/lib/python3.11/dist-packages (4.47.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.47.0) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.0) (2025.7.14)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8eb9ed0c6414ed187049026305e0aa8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'USER:  What are the things that you see in the picture? What stands out to you the most?\\n ASSISTANT:  In the picture, there is a white car parked on a city street, with a tall building in the background. The car is parked on the side of the road, and it stands out to me the most. The presence of the car and the tall building in the background create a sense of urban life and activity.'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_string = output[0]['generated_text']\n",
        "\n",
        "# Find the start and end of the ASSISTANT's message\n",
        "assistant_start = output_string.find(\"ASSISTANT: \") + len(\"ASSISTANT: \")\n",
        "\n",
        "# Extract the assistant's message\n",
        "assistant_message = output_string[assistant_start:].strip() # Use strip() to remove leading/trailing whitespace\n",
        "\n",
        "# Split the message into sentences (or rough points)\n",
        "# This is a simple split by common sentence endings.\n",
        "# More complex parsing might be needed for more nuanced splitting.\n",
        "points = assistant_message.split('. ')\n",
        "\n",
        "for point in points:\n",
        "    if point: # Avoid printing empty strings\n",
        "        print(f\"- {point.strip()}\") # Add a hyphen and space for bullet points and strip whitespace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaFLf6iBJUdx",
        "outputId": "da5c89cc-9069-4160-e063-bd0639ed62bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- In the picture, there is a white car parked on a city street, with a tall building in the background\n",
            "- The car is parked on the side of the road, and it stands out to me the most\n",
            "- The presence of the car and the tall building in the background create a sense of urban life and activity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDqpRgyrK9MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NEW MODEL\n",
        "\n",
        "##wav2vec : developed by meta\n",
        "\n",
        "1. Revolutionary approach in speech recognization and audio processing.\n",
        "2. Developed by Facebook, now maninained by META,\n",
        "3. Designed to learn powerful represenatation of speech audio from unlabelled data\n",
        "wav2vec models are designed to learn powerful representations of speech audio from unlabeled data.\n",
        "4. The key feature of wav2vec lies in the self-supervised learning approach.\n",
        "5. It can extract meaningful features from raw audio waveforms without requiring transcribed text, which is often expensive and time-consuming to obtain.\n",
        "6. This makes wav2vec particularly useful for low-resource languages or specialized domains where labeled data is really scarce.\n",
        "7. wav2vec models have shown impressive performance in various speech recognition tasks, often matching or surpassing the traditional supervised approaches.\n",
        "8. They've been successfully applied to tasks like\n",
        "-  speech recognition,\n",
        "- speaker identification, and even\n",
        "- music processing,\n",
        "showcasing their versatility in handling all your data.\n",
        "9. This model will form the backbone of our automatic speech recognition system."
      ],
      "metadata": {
        "id": "zh4Mr2dIMdX1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vS7M_9HzNlbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}